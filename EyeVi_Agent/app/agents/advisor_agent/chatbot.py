#!/usr/bin/env python3
"""
Chatbot Class cho PDF RAG System
Xá»­ lÃ½ queries tá»« user dá»±a trÃªn dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c náº¡p vÃ o vector database
"""

from typing import Dict, List, Optional
from utils.embedding_manager import EmbeddingManager
from utils.qdrant_manager import QdrantManager
from agents.rag_agent import RAGAgent
from config import Config

class PDFChatbot:
    def __init__(self):
        """
        Khá»Ÿi táº¡o Chatbot vá»›i cÃ¡c components cáº§n thiáº¿t cho query processing
        """
        print("ðŸ¤– Khá»Ÿi táº¡o PDF Chatbot...")
        
        # Chá»‰ khá»Ÿi táº¡o components cáº§n thiáº¿t cho chat
        self.embedding_manager = EmbeddingManager()
        self.qdrant_manager = QdrantManager()
        self.rag_agent = RAGAgent()
        
        # Kiá»ƒm tra káº¿t ná»‘i vÃ  dá»¯ liá»‡u
        self._check_readiness()
        
        print("âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng!")
    
    def _check_readiness(self):
        """
        Kiá»ƒm tra xem chatbot cÃ³ sáºµn sÃ ng xá»­ lÃ½ queries khÃ´ng
        """
        try:
            # Kiá»ƒm tra collection cÃ³ dá»¯ liá»‡u khÃ´ng
            collection_info = self.qdrant_manager.get_collection_info()
            
            if "error" in collection_info:
                raise Exception(f"Collection khÃ´ng tá»“n táº¡i: {collection_info['error']}")
            
            vector_count = collection_info.get('vectors_count', 0)
            if vector_count == 0:
                raise Exception("Collection rá»—ng, cáº§n cháº¡y data ingestion trÆ°á»›c")
            
            print(f"ðŸ“Š Collection ready: {vector_count} vectors")
            
        except Exception as e:
            print(f"âš ï¸  Cáº£nh bÃ¡o: {e}")
            print("ðŸ’¡ HÃ£y cháº¡y script ingest_data.py trÆ°á»›c khi sá»­ dá»¥ng chatbot")
    
    def invoke(self, query: str, **kwargs) -> Dict:
        """
        Method chÃ­nh Ä‘á»ƒ xá»­ lÃ½ má»™t cÃ¢u há»i tá»« user
        
        Args:
            query: CÃ¢u há»i cá»§a user
            **kwargs: CÃ¡c tham sá»‘ tÃ¹y chá»n
                - top_k: Sá»‘ documents tá»‘i Ä‘a Ä‘á»ƒ retrieve (default tá»« config)
                - similarity_threshold: NgÆ°á»¡ng similarity (default tá»« config)
                - verbose: In chi tiáº¿t quÃ¡ trÃ¬nh xá»­ lÃ½
        
        Returns:
            Dict chá»©a káº¿t quáº£:
            {
                "query": str,
                "answer": str,
                "sources": List[str],
                "relevant_docs_count": int,
                "total_retrieved_count": int,
                "status": str,
                "error": str (náº¿u cÃ³),
                "metadata": Dict (thÃ´ng tin bá»• sung)
            }
        """
        if not query or not query.strip():
            return {
                "query": query,
                "answer": "Xin lá»—i, báº¡n chÆ°a Ä‘áº·t cÃ¢u há»i gÃ¬.",
                "sources": [],
                "relevant_docs_count": 0,
                "total_retrieved_count": 0,
                "status": "error",
                "error": "Query rá»—ng",
                "metadata": {}
            }
        
        verbose = kwargs.get('verbose', False)
        
        try:
            if verbose:
                print(f"â“ Äang xá»­ lÃ½: {query}")
            
            # BÆ°á»›c 1: Táº¡o embedding cho query
            query_embedding = self._create_query_embedding(query, verbose)
            
            # BÆ°á»›c 2: Retrieve documents tá»« vector DB
            retrieved_docs = self._retrieve_documents(
                query_embedding, 
                top_k=kwargs.get('top_k'),
                similarity_threshold=kwargs.get('similarity_threshold'),
                verbose=verbose
            )
            
            # BÆ°á»›c 3: Xá»­ lÃ½ vá»›i RAG Agent
            result = self._process_with_rag_agent(query, retrieved_docs, verbose)
            
            if verbose:
                print(f"âœ… HoÃ n thÃ nh xá»­ lÃ½ query")
            
            return result
            
        except Exception as e:
            error_msg = f"Lá»—i khi xá»­ lÃ½ query: {str(e)}"
            if verbose:
                print(f"âŒ {error_msg}")
            
            return {
                "query": query,
                "answer": f"Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n: {error_msg}",
                "sources": [],
                "relevant_docs_count": 0,
                "total_retrieved_count": 0,
                "status": "error",
                "error": error_msg,
                "metadata": {}
            }
    
    def _create_query_embedding(self, query: str, verbose: bool = False) -> List[float]:
        """
        Táº¡o embedding cho query
        """
        if verbose:
            print("ðŸ§® Táº¡o embedding cho query...")
        
        query_embedding = self.embedding_manager.embed_query(query)
        return query_embedding.tolist()
    
    def _retrieve_documents(self, query_embedding: List[float], top_k: Optional[int] = None, 
                           similarity_threshold: Optional[float] = None, verbose: bool = False) -> List[Dict]:
        """
        Retrieve documents tá»« vector database
        """
        if verbose:
            print("ðŸ” TÃ¬m kiáº¿m documents liÃªn quan...")
        
        # Sá»­ dá»¥ng config máº·c Ä‘á»‹nh náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p
        actual_top_k = top_k or Config.TOP_K_DOCUMENTS
        actual_threshold = similarity_threshold or Config.SIMILARITY_THRESHOLD
        
        # Temporarily override config náº¿u cáº§n
        original_top_k = Config.TOP_K_DOCUMENTS
        original_threshold = Config.SIMILARITY_THRESHOLD
        
        try:
            Config.TOP_K_DOCUMENTS = actual_top_k
            Config.SIMILARITY_THRESHOLD = actual_threshold
            
            retrieved_docs = self.qdrant_manager.search_similar_documents(query_embedding)
            
            if verbose:
                print(f"ðŸ“„ TÃ¬m tháº¥y {len(retrieved_docs)} documents")
            
            return retrieved_docs
            
        finally:
            # Restore original config
            Config.TOP_K_DOCUMENTS = original_top_k
            Config.SIMILARITY_THRESHOLD = original_threshold
    
    def _process_with_rag_agent(self, query: str, retrieved_docs: List[Dict], verbose: bool = False) -> Dict:
        """
        Xá»­ lÃ½ vá»›i RAG Agent Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
        """
        if verbose:
            print("ðŸ¤– Táº¡o cÃ¢u tráº£ lá»i vá»›i RAG Agent...")
        
        result = self.rag_agent.process_query(query, retrieved_docs)
        
        # ThÃªm metadata
        result["status"] = "success"
        result["metadata"] = {
            "embedding_model": Config.EMBEDDING_MODEL,
            "llm_model": Config.GEMINI_MODEL,
            "collection_name": Config.COLLECTION_NAME,
            "similarity_threshold": Config.SIMILARITY_THRESHOLD,
            "top_k": Config.TOP_K_DOCUMENTS
        }
        
        return result
    
    def get_collection_stats(self) -> Dict:
        """
        Láº¥y thá»‘ng kÃª vá» collection hiá»‡n táº¡i
        """
        try:
            collection_info = self.qdrant_manager.get_collection_info()
            return {
                "status": "success",
                "collection_name": Config.COLLECTION_NAME,
                "vectors_count": collection_info.get('vectors_count', 0),
                "indexed_vectors_count": collection_info.get('indexed_vectors_count', 0),
                "collection_status": collection_info.get('status', 'unknown')
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def health_check(self) -> Dict:
        """
        Kiá»ƒm tra sá»©c khá»e cá»§a chatbot
        """
        try:
            # Test embedding
            test_embedding = self.embedding_manager.embed_query("test")
            embedding_ok = len(test_embedding) > 0
            
            # Test Qdrant
            collection_info = self.qdrant_manager.get_collection_info()
            qdrant_ok = "error" not in collection_info
            
            # Test RAG Agent (lightweight test)
            rag_ok = self.rag_agent is not None
            
            overall_status = embedding_ok and qdrant_ok and rag_ok
            
            return {
                "status": "healthy" if overall_status else "unhealthy",
                "components": {
                    "embedding_manager": "ok" if embedding_ok else "error",
                    "qdrant_manager": "ok" if qdrant_ok else "error", 
                    "rag_agent": "ok" if rag_ok else "error"
                },
                "collection_vectors": collection_info.get('vectors_count', 0) if qdrant_ok else 0,
                "embedding_dimension": len(test_embedding) if embedding_ok else 0
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def batch_invoke(self, queries: List[str], **kwargs) -> List[Dict]:
        """
        Xá»­ lÃ½ nhiá»u queries cÃ¹ng lÃºc
        """
        verbose = kwargs.get('verbose', False)
        
        if verbose:
            print(f"ðŸ“ Xá»­ lÃ½ batch {len(queries)} queries...")
        
        results = []
        for i, query in enumerate(queries, 1):
            if verbose:
                print(f"\n[{i}/{len(queries)}] Processing: {query[:50]}...")
            
            result = self.invoke(query, verbose=False, **kwargs)
            results.append(result)
        
        if verbose:
            print(f"âœ… HoÃ n thÃ nh batch processing")
        
        return results

# Convenience function Ä‘á»ƒ táº¡o chatbot instance
def create_chatbot() -> PDFChatbot:
    """
    Factory function Ä‘á»ƒ táº¡o chatbot instance
    """
    return PDFChatbot()

# Singleton instance (tÃ¹y chá»n)
_chatbot_instance = None

def get_chatbot() -> PDFChatbot:
    """
    Láº¥y singleton instance cá»§a chatbot
    """
    global _chatbot_instance
    if _chatbot_instance is None:
        _chatbot_instance = PDFChatbot()
    return _chatbot_instance 