# Há»‡ thá»‘ng Há»i-ÄÃ¡p TÃ i liá»‡u PDF sá»­ dá»¥ng LangGraph, RAG vÃ  Qdrant

Má»™t há»‡ thá»‘ng thÃ´ng minh cÃ³ kháº£ nÄƒng hiá»ƒu cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ  tráº£ lá»i dá»±a trÃªn ná»™i dung cá»§a cÃ¡c tÃ i liá»‡u PDF Ä‘Æ°á»£c cung cáº¥p. Há»‡ thá»‘ng táº­n dá»¥ng sá»©c máº¡nh cá»§a LangGraph Ä‘á»ƒ Ä‘iá»u phá»‘i cÃ¡c tÃ¡c vá»¥, ká»¹ thuáº­t RAG Ä‘á»ƒ káº¿t há»£p truy xuáº¥t thÃ´ng tin vá»›i kháº£ nÄƒng sinh vÄƒn báº£n, vÃ  Qdrant lÃ m cÆ¡ sá»Ÿ dá»¯ liá»‡u vector.

**ğŸ†• Kiáº¿n trÃºc má»›i: TÃ¡ch biá»‡t Data Ingestion + Chatbot Class**  
**ğŸ“ Sá»­ dá»¥ng thÆ° má»¥c `data/` máº·c Ä‘á»‹nh**

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

### Kiáº¿n trÃºc TÃ¡ch biá»‡t (Má»›i)

![Kiáº¿n trÃºc há»‡ thá»‘ng](docs/RAG.png)

1. **ğŸ“¥ Data Ingestion Script** (`ingest_data.py`)
   - Xá»­ lÃ½ PDF tá»« thÆ° má»¥c `data/` â†’ Embedding â†’ Vector DB
   - Chá»‰ cháº¡y khi cÃ³ dá»¯ liá»‡u má»›i
   - Independent pipeline

2. **ğŸ¤– Chatbot Class** (`chatbot.py`)  
   - Query Processing â†’ RAG â†’ Response
   - Method `invoke()` cho má»—i chat
   - Production-ready

### CÃ¡c thÃ nh pháº§n chÃ­nh

- **LangGraph**: Äiá»u phá»‘i workflow vÃ  quáº£n lÃ½ tráº¡ng thÃ¡i
- **RAG (Retrieval Augmented Generation)**: Truy xuáº¥t thÃ´ng tin + sinh cÃ¢u tráº£ lá»i
- **Qdrant**: CÆ¡ sá»Ÿ dá»¯ liá»‡u vector Ä‘á»ƒ lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m
- **Sentence Transformers**: MÃ´ hÃ¬nh embedding
- **Google Gemini**: MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (thay tháº¿ OpenAI GPT)

### Workflow

#### Giai Ä‘oáº¡n 1: Data Ingestion (script - má»™t láº§n)
```bash
# Äáº·t PDF vÃ o data/ vÃ  cháº¡y
python ingest_data.py
```
1. **Táº£i vÃ  phÃ¢n tÃ¡ch PDF** â†’ Chia thÃ nh chunks
2. **Táº¡o embeddings** â†’ Chuyá»ƒn text thÃ nh vectors
3. **LÆ°u vÃ o Qdrant** â†’ Láº­p chá»‰ má»¥c vectors

#### Giai Ä‘oáº¡n 2: Chatbot Usage (class - má»—i query)
```python
result = chatbot.invoke("CÃ¢u há»i cá»§a tÃ´i")
```
1. **Xá»­ lÃ½ cÃ¢u há»i** â†’ Táº¡o query embedding
2. **Truy xuáº¥t tÃ i liá»‡u** â†’ TÃ¬m chunks liÃªn quan
3. **ÄÃ¡nh giÃ¡ vÃ  lá»c** â†’ Chá»n ná»™i dung cháº¥t lÆ°á»£ng
4. **Tá»•ng há»£p ngá»¯ cáº£nh** â†’ Káº¿t há»£p thÃ´ng tin
5. **Táº¡o cÃ¢u tráº£ lá»i** â†’ Sá»­ dá»¥ng Google Gemini

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- Qdrant server (local hoáº·c cloud)
- Google API key (Gemini)

### 2. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 3. Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

#### Láº¥y Google API Key:
1. Truy cáº­p https://makersuite.google.com/app/apikey
2. Táº¡o API key má»›i
3. Copy API key

#### Táº¡o file `.env` hoáº·c export biáº¿n mÃ´i trÆ°á»ng:

```bash
export GOOGLE_API_KEY="your_google_api_key_here"
export GEMINI_MODEL="gemini-1.5-flash"  # hoáº·c gemini-1.5-pro
export QDRANT_URL="http://localhost:6333"
export QDRANT_API_KEY=""  # TÃ¹y chá»n náº¿u dÃ¹ng Qdrant Cloud
```

### 4. Khá»Ÿi Ä‘á»™ng Qdrant server

```bash
# Sá»­ dá»¥ng Docker
docker run -p 6333:6333 qdrant/qdrant

# Hoáº·c sá»­ dá»¥ng docker-compose
docker-compose up -d
```

## ğŸš€ Sá»­ dá»¥ng (ÄÆ¡n giáº£n vá»›i thÆ° má»¥c data/)

### 1. Setup láº§n Ä‘áº§u

```bash
# HÆ°á»›ng dáº«n setup tá»«ng bÆ°á»›c
python main.py setup
```

### 2. Quy trÃ¬nh nhanh (3 bÆ°á»›c)

```bash
# BÆ°á»›c 1: Äáº·t PDF vÃ o thÆ° má»¥c data
mkdir data
cp your_files.pdf data/

# BÆ°á»›c 2: Náº¡p dá»¯ liá»‡u
python ingest_data.py

# BÆ°á»›c 3: Sá»­ dá»¥ng chatbot
python main.py demo
```

### 3. Cáº¥u trÃºc thÆ° má»¥c data

```
data/
â”œâ”€â”€ research_papers/
â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â””â”€â”€ paper2.pdf
â”œâ”€â”€ manuals/
â”‚   â”œâ”€â”€ user_guide.pdf
â”‚   â””â”€â”€ technical_spec.pdf
â””â”€â”€ reports/
    â””â”€â”€ annual_report.pdf
```

### 4. Commands chÃ­nh

```bash
# Data ingestion
python ingest_data.py              # Náº¡p tá»« data/
python ingest_data.py --clear      # XÃ³a dá»¯ liá»‡u cÅ©
python ingest_data.py --check      # Kiá»ƒm tra há»‡ thá»‘ng

# Chatbot usage
python main.py demo                # Demo vá»›i cÃ¢u há»i máº«u
python main.py interactive         # Chat tÆ°Æ¡ng tÃ¡c
python main.py check               # Kiá»ƒm tra tráº¡ng thÃ¡i
python main.py setup               # HÆ°á»›ng dáº«n setup
```

### 5. Sá»­ dá»¥ng trong code

```python
from chatbot import create_chatbot

# Táº¡o chatbot instance
chatbot = create_chatbot()

# Invoke method cho má»—i query
result = chatbot.invoke("TÃ i liá»‡u nÃ y nÃ³i vá» gÃ¬?")

if result["status"] == "success":
    print(f"Tráº£ lá»i: {result['answer']}")
    print(f"Nguá»“n: {result['sources']}")
else:
    print(f"Lá»—i: {result['error']}")
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
advisor_agent/
â”œâ”€â”€ data/                         # ğŸ“ ThÆ° má»¥c chá»©a PDF files
â”‚   â”œâ”€â”€ .gitkeep                  # Keep folder trong git
â”‚   â””â”€â”€ your_files.pdf            # Äáº·t PDF á»Ÿ Ä‘Ã¢y
â”œâ”€â”€ ingest_data.py                # ğŸ“¥ Script náº¡p dá»¯ liá»‡u PDF
â”œâ”€â”€ chatbot.py                    # ğŸ¤– Chatbot class vá»›i invoke method
â”œâ”€â”€ main.py                       # ğŸš€ Main application
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rag_agent.py              # Agent xá»­ lÃ½ RAG vá»›i Gemini
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_processor.py          # Xá»­ lÃ½ PDF
â”‚   â”œâ”€â”€ embedding_manager.py      # Quáº£n lÃ½ embeddings
â”‚   â””â”€â”€ qdrant_manager.py         # Quáº£n lÃ½ Qdrant
â”œâ”€â”€ workflow/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ langgraph_workflow.py     # LangGraph workflow (legacy)
â”œâ”€â”€ config.py                     # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ USAGE.md                      # ğŸ“– HÆ°á»›ng dáº«n chi tiáº¿t
â”œâ”€â”€ document.md                   # TÃ i liá»‡u workflow gá»‘c
â””â”€â”€ README.md                     # HÆ°á»›ng dáº«n nÃ y
```

## âš™ï¸ Æ¯u Ä‘iá»ƒm Kiáº¿n trÃºc Má»›i

### ğŸ”„ TÃ¡ch biá»‡t Concerns
- **Data Ingestion**: Xá»­ lÃ½ PDF Ä‘á»™c láº­p tá»« thÆ° má»¥c `data/`
- **Query Processing**: Chatbot class chuyÃªn dá»¥ng  
- **Performance**: KhÃ´ng load PDF processing má»—i láº§n chat

### ğŸš€ Production Ready
- **Modular**: Dá»… maintain vÃ  scale
- **Efficient**: Load model má»™t láº§n, sá»­ dá»¥ng nhiá»u láº§n
- **Flexible**: CÃ³ thá»ƒ integrate vÃ o web API, CLI, notebook

### ğŸ’» Developer Friendly
- **Simple API**: `chatbot.invoke(query)`
- **Rich Response**: Status, sources, metadata
- **Error Handling**: Graceful error recovery
- **Monitoring**: Health check, stats

### ğŸ“ Data Management
- **Default Folder**: ThÆ° má»¥c `data/` máº·c Ä‘á»‹nh
- **Auto Discovery**: Tá»± Ä‘á»™ng tÃ¬m PDF trong subfolders
- **Easy Setup**: Copy PDF vÃ o data/ vÃ  cháº¡y script

## ğŸ”§ Cáº¥u hÃ¬nh

Chá»‰nh sá»­a `config.py` Ä‘á»ƒ tÃ¹y chá»‰nh:

```python
class Config:
    # Google Gemini API
    GOOGLE_API_KEY = "your_key"
    GEMINI_MODEL = "gemini-1.5-flash"  # hoáº·c gemini-1.5-pro
    
    # Database
    QDRANT_URL = "http://localhost:6333"
    
    # Models
    EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
    
    # Chunking
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    
    # Retrieval
    TOP_K_DOCUMENTS = 5
    SIMILARITY_THRESHOLD = 0.7
    
    # Gemini settings
    GEMINI_TEMPERATURE = 0.1
    GEMINI_MAX_OUTPUT_TOKENS = 2048
```

## ğŸ¤– Google Gemini Models

### CÃ¡c model cÃ³ sáºµn:
- **gemini-1.5-flash**: Nhanh, phÃ¹ há»£p cho háº§u háº¿t tÃ¡c vá»¥
- **gemini-1.5-pro**: Cháº¥t lÆ°á»£ng cao hÆ¡n, cháº­m hÆ¡n
- **gemini-1.0-pro**: PhiÃªn báº£n cÅ© hÆ¡n

### Æ¯u Ä‘iá»ƒm cá»§a Gemini:
- **Miá»…n phÃ­**: API cÃ³ quota miá»…n phÃ­ hÃ o phÃ³ng
- **Äa ngÃ´n ngá»¯**: Há»— trá»£ tiáº¿ng Viá»‡t tá»‘t
- **Context dÃ i**: Há»— trá»£ context window lá»›n
- **Hiá»‡u suáº¥t**: Tá»‘c Ä‘á»™ response nhanh

## ğŸ’¡ VÃ­ dá»¥ sá»­ dá»¥ng

### 1. Web API Integration

```python
from fastapi import FastAPI
from chatbot import get_chatbot

app = FastAPI()
chatbot = get_chatbot()  # Singleton

@app.post("/chat")
async def chat(query: str):
    result = chatbot.invoke(query)
    return {
        "answer": result["answer"],
        "sources": result["sources"],
        "status": result["status"]
    }
```

### 2. CLI Application

```python
from chatbot import create_chatbot

chatbot = create_chatbot()

while True:
    query = input("Question: ")
    if query == 'exit':
        break
    
    result = chatbot.invoke(query)
    print(f"Answer: {result['answer']}")
```

### 3. Batch Processing

```python
questions = [
    "Váº¥n Ä‘á» chÃ­nh lÃ  gÃ¬?",
    "PhÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c sá»­ dá»¥ng?",
    "Káº¿t luáº­n quan trá»ng?"
]

results = chatbot.batch_invoke(questions)
for q, r in zip(questions, results):
    print(f"Q: {q}\nA: {r['answer']}\n")
```

## ğŸ› ï¸ API Reference

### DataIngestionPipeline (ingest_data.py)

#### Methods
- `run_ingestion(pdf_paths=None, clear_existing=False)`: Náº¡p dá»¯ liá»‡u PDF
- `check_prerequisites()`: Kiá»ƒm tra tiÃªn quyáº¿t
- `check_data_folder()`: Kiá»ƒm tra thÆ° má»¥c data

#### Usage
```bash
python ingest_data.py              # Máº·c Ä‘á»‹nh tá»« data/
python ingest_data.py path/        # Tá»« path cá»¥ thá»ƒ
python ingest_data.py --clear      # XÃ³a collection cÅ©
python ingest_data.py --check      # Chá»‰ kiá»ƒm tra
```

### PDFChatbot (chatbot.py)

#### Main Methods
- `invoke(query, **kwargs)`: Xá»­ lÃ½ má»™t cÃ¢u há»i
- `batch_invoke(queries, **kwargs)`: Xá»­ lÃ½ nhiá»u cÃ¢u há»i
- `health_check()`: Kiá»ƒm tra sá»©c khá»e
- `get_collection_stats()`: Thá»‘ng kÃª collection

#### Invoke Parameters
- `query`: CÃ¢u há»i (required)
- `top_k`: Sá»‘ documents retrieve (optional)
- `similarity_threshold`: NgÆ°á»¡ng similarity (optional)  
- `verbose`: In chi tiáº¿t quÃ¡ trÃ¬nh (optional)

#### Response Format
```python
{
    "query": str,
    "answer": str,
    "sources": List[str],
    "relevant_docs_count": int,
    "total_retrieved_count": int,
    "status": str,  # "success" or "error"
    "error": str,   # náº¿u cÃ³ lá»—i
    "metadata": Dict
}
```

## ğŸ” Troubleshooting

### 1. Lá»—i thÆ° má»¥c data

```bash
# Táº¡o thÆ° má»¥c vÃ  Ä‘áº·t PDF
mkdir data
cp your_files.pdf data/

# Kiá»ƒm tra
python main.py check
```

### 2. Lá»—i Collection rá»—ng

```bash
# Kiá»ƒm tra vÃ  náº¡p dá»¯ liá»‡u
python ingest_data.py --check
python ingest_data.py
```

### 3. Lá»—i káº¿t ná»‘i Qdrant

```bash
# Kiá»ƒm tra Qdrant Ä‘ang cháº¡y
curl http://localhost:6333/health
docker-compose ps

# Restart náº¿u cáº§n
docker-compose restart
```

### 4. Lá»—i Google Gemini API

```python
# Test trong code
from chatbot import create_chatbot
chatbot = create_chatbot()
health = chatbot.health_check()
print(health)
```

### 5. Setup tá»« Ä‘áº§u

```bash
# Cháº¡y setup guide
python main.py setup
```

## ğŸ“Š Monitoring vÃ  Logging

### Logging Output
```
ğŸ”§ Khá»Ÿi táº¡o Data Ingestion Pipeline...
âœ… TÃ¬m tháº¥y 5 PDF files trong data/
ğŸ“„ Báº¯t Ä‘áº§u xá»­ lÃ½ 5 PDF files...
ğŸ§® Táº¡o embeddings cho 150 documents...
ğŸ’¾ LÆ°u 150 documents vÃ o Qdrant...
âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng!

ğŸ¤– Khá»Ÿi táº¡o PDF Chatbot...
ğŸ“Š Collection ready: 150 vectors
âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng!
```

### Health Monitoring
```python
# Äá»‹nh ká»³ check health
health = chatbot.health_check()
if health["status"] != "healthy":
    # Alert or restart
    print(f"Chatbot unhealthy: {health}")
```

## ğŸš€ Production Deployment

### 1. Environment Setup
```bash
# Production environment
export GOOGLE_API_KEY="production_key"
export GEMINI_MODEL="gemini-1.5-pro"
export QDRANT_URL="https://your-qdrant-cloud.com"
export QDRANT_API_KEY="production_qdrant_key"
```

### 2. Data Pipeline
```bash
# Batch job cho data ingestion
cron: 0 2 * * * /path/to/python ingest_data.py --clear
```

### 3. Application Integration  
```python
# Singleton trong production
from chatbot import get_chatbot

# Application startup
chatbot = get_chatbot()

# Request handling
def handle_request(user_query):
    return chatbot.invoke(user_query)
```

## ğŸ’° Chi phÃ­ vÃ  Limits

### Google Gemini (miá»…n phÃ­):
- **Gemini 1.5 Flash**: 15 requests/minute, 1M tokens/day
- **Gemini 1.5 Pro**: 2 requests/minute, 50 requests/day

### So sÃ¡nh vá»›i OpenAI:
| Feature | Google Gemini | OpenAI GPT |
|---------|---------------|------------|
| Cost | Miá»…n phÃ­ (cÃ³ limit) | Tráº£ phÃ­ theo usage |
| Speed | Nhanh | Trung bÃ¬nh |
| Vietnamese | Tá»‘t | Ráº¥t tá»‘t |
| Context | 32k - 2M tokens | 4k - 128k tokens |

## ğŸ“– TÃ i liá»‡u thÃªm

- **[USAGE.md](docs/USAGE.md)**: HÆ°á»›ng dáº«n sá»­ dá»¥ng chi tiáº¿t
- **[document.md](docs/document.md)**: TÃ i liá»‡u workflow gá»‘c
- **[EMBEDDING_GUIDE.md](docs/EMBEDDING_GUIDE.md)**: HÆ°á»›ng dáº«n embedding, lá»±a chá»n mÃ´ hÃ¬nh
- **[EYEWEAR_DOMAIN_GUIDE.md](docs/EYEWEAR_DOMAIN_GUIDE.md)**: HÆ°á»›ng dáº«n tá»‘i Æ°u hÃ³a cho domain máº¯t kÃ­nh
- **[EYEWEAR_DOMAIN_GUIDE.md](docs/EYEWEAR_DOMAIN_GUIDE.md)**: HÆ°á»›ng dáº«n tá»‘i Æ°u hÃ³a cho domain máº¯t kÃ­nh
- **[README_A2A.md](docs/README_A2A.md)**: TÃ i liá»‡u A2A cho advisor agent


## ğŸ“œ License

MIT License

## ğŸ¤ Contributing

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push vÃ  táº¡o Pull Request

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», hÃ£y:
1. Cháº¡y `python main.py setup` Ä‘á»ƒ kiá»ƒm tra
2. Kiá»ƒm tra logs chi tiáº¿t
3. Tham kháº£o Troubleshooting
4. Xem USAGE.md
5. Táº¡o issue trÃªn GitHub

---

**TÃ¡c giáº£**: AI Assistant  
**PhiÃªn báº£n**: 3.1.0 (Data Folder Architecture)  
**Cáº­p nháº­t**: 2024

**ğŸ”— Quick Start:**
1. ğŸ“ `mkdir data && cp *.pdf data/`
2. ğŸ“¥ `python ingest_data.py`
3. ğŸ¤– `python main.py demo`

**ğŸ“– Chi tiáº¿t:** [USAGE.md](USAGE.md) 